{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "customers = pd.read_csv('customers_tm1_e.csv')\n",
    "transactions = pd.read_csv('transactions_tm1_e.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Brief Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customers.shape)\n",
    "print(customers.columns)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transactions.shape)\n",
    "print(transactions.columns)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions['customer_id']==92]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Creating the Combined Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataframe of Useful Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset containing relevant columns\n",
    "df = customers[['customer_id','dob','state','start_balance','creation_date']]\n",
    "\n",
    "# adding some columns to new dataset\n",
    "\n",
    "# final transaction date\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date']) # convert datetime\n",
    "last_transaction = transactions.groupby('customer_id', as_index=False)['transaction_date'].max() # create table of last transaction and customer id\n",
    "last_transaction.rename(columns={'transaction_date':'final_transaction_date'},inplace=True) # rename\n",
    "df = df.merge(last_transaction, how='left', on='customer_id') # merge to new df\n",
    "\n",
    "# final deposit date\n",
    "transactions['deposit_date'] = pd.to_datetime(transactions['transaction_date']) # convert datetime\n",
    "last_transaction = transactions[transactions[\"deposit\"] > 0].groupby('customer_id', as_index=False)['deposit_date'].max() # create table of last transaction and customer id\n",
    "last_transaction.rename(columns={'deposit_date':'final_deposit_date'},inplace=True) # rename\n",
    "df = df.merge(last_transaction, how='left', on='customer_id') # merge to new df\n",
    "\n",
    "# first transaction date\n",
    "first_transaction = transactions.groupby('customer_id', as_index=False)['transaction_date'].min()\n",
    "first_transaction.rename(columns={'transaction_date':'first_transaction_date'},inplace=True)\n",
    "df = df.merge(first_transaction, how='left', on='customer_id')\n",
    "\n",
    "# total deposits\n",
    "tot_deposits = transactions.groupby('customer_id', as_index=False)['deposit'].sum()\n",
    "tot_deposits.rename(columns={'deposit':'total_deposits'}, inplace=True)\n",
    "df = df.merge(tot_deposits, how='left', on='customer_id')\n",
    "\n",
    "# total withdrawals\n",
    "tot_withdraws = transactions.groupby('customer_id', as_index=False)['withdrawal'].sum()\n",
    "tot_withdraws.rename(columns={'withdrawal':'total_withdrawals'}, inplace=True)\n",
    "df = df.merge(tot_withdraws, how='left', on='customer_id')\n",
    "\n",
    "# total deposits\n",
    "num_deposits = transactions.groupby('customer_id', as_index=False)['deposit'].count()\n",
    "num_deposits.rename(columns={'deposit':'num_of_deposits'}, inplace=True)\n",
    "df = df.merge(num_deposits, how='left', on='customer_id')\n",
    "\n",
    "# total withdrawals\n",
    "num_withdraws = transactions.groupby('customer_id', as_index=False)['withdrawal'].count()\n",
    "num_withdraws.rename(columns={'withdrawal':'num_of_withdrawals'}, inplace=True)\n",
    "df = df.merge(num_withdraws, how='left', on='customer_id')\n",
    "\n",
    "# final balance\n",
    "df['final_balance'] = df['start_balance'] + df['total_deposits'] + df['total_withdrawals']\n",
    "\n",
    "# duration open\n",
    "df['creation_date'] = pd.to_datetime(df['creation_date'])\n",
    "df['duration_open'] = (df['final_transaction_date'] - df['first_transaction_date'])\n",
    "df['duration_open'] = df['duration_open'].dt.days\n",
    "\n",
    "# age on final transaction date\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['age'] = (((df['final_transaction_date'] - df['dob']).dt.days)/365).apply(np.floor)\n",
    "\n",
    "# avg deposits\n",
    "avg_deposits = transactions.groupby('customer_id', as_index=False)['deposit'].mean()\n",
    "avg_deposits.rename(columns={'deposit':'avg_deposit_val'}, inplace=True)\n",
    "df = df.merge(avg_deposits, how='left', on='customer_id')\n",
    "\n",
    "# avg withdrawals\n",
    "avg_withdrawals = transactions.groupby('customer_id', as_index=False)['withdrawal'].mean()\n",
    "avg_withdrawals.rename(columns={'withdrawal':'avg_withdrawal_val'}, inplace=True)\n",
    "df = df.merge(avg_withdrawals, how='left', on='customer_id')\n",
    "\n",
    "# number of deposits and withdrawals\n",
    "transactions['deposit_with_nas'] = transactions['deposit'].replace({0:np.nan})\n",
    "transactions['withdrawal_with_nas'] = transactions['withdrawal'].replace({0:np.nan})\n",
    "new_df = transactions[['customer_id','deposit_with_nas','withdrawal_with_nas']]\n",
    "df = df.merge(new_df.groupby('customer_id')['deposit_with_nas'].agg('count'), how='left', on='customer_id')\n",
    "df = df.merge(new_df.groupby('customer_id')['withdrawal_with_nas'].agg('count'), how='left', on='customer_id')\n",
    "df.rename(columns={'deposit_with_nas':'num_deposits','withdrawal_with_nas':'num_withdrawals'}, inplace=True)\n",
    "\n",
    "# get the regions\n",
    "state_groups = {'Northeast': ['New York', 'Pennsylvania', 'New Jersey', 'Connecticut', 'Massachusetts', 'Rhode Island', 'Maine', 'Vermont', 'New Hampshire'],\n",
    "                'Midwest': ['Illinois', 'Ohio', 'Michigan', 'Indiana', 'Wisconsin', 'Minnesota', 'Iowa', 'Missouri', 'North Dakota', 'South Dakota', 'Nebraska', 'Kansas'],\n",
    "                'South': ['Texas', 'Florida', 'North Carolina', 'Georgia', 'Virginia', 'Tennessee', 'South Carolina', 'Alabama', 'Louisiana', 'Kentucky', 'Oklahoma', 'Arkansas', 'West Virginia', 'Mississippi'],\n",
    "                'West': ['California', 'Washington', 'Arizona', 'Colorado', 'Oregon', 'Utah', 'Nevada', 'New Mexico', 'Idaho', 'Montana', 'Wyoming', 'Alaska', 'Hawaii', 'District of Columbia', 'Delaware']}\n",
    "state_to_region = {}\n",
    "for region, states in state_groups.items():\n",
    "    for state in states:\n",
    "        state_to_region[state] = region\n",
    "# Apply the mapping to the 'state' column to create a new 'Region' column\n",
    "df[\"region\"] = df['state'].apply(lambda x: state_to_region[x] if x in state_to_region else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # get the time difference between each deposit\n",
    "# transaction_df = transactions.sort_values(by=['customer_id', 'transaction_date'])\n",
    "# transaction_df['transaction_diff'] = (transaction_df[transaction_df['deposit'] > 0].groupby('customer_id')['transaction_date'].diff().dt.days)\n",
    "# transaction_df = transaction_df[transaction_df['transaction_diff'].notna()]\n",
    "\n",
    "# transaction_df['avg_transaction_diff'] = (transaction_df[transaction_df['deposit'] > 0].groupby('customer_id')['transaction_date'].diff().dt.days.mean())\n",
    "# transaction_df = transaction_df[transaction_df['avg_transaction_diff'].notna()]\n",
    "\n",
    "# # Calculate the number of days in the dataset\n",
    "# # diff = transaction_df['avg_transaction_diff']\n",
    "# # print(diff.describe())\n",
    "# print(transaction_df.head(100))\n",
    "# # num_days = (diff.max() - diff.min())\n",
    "\n",
    "# # # Create a histogram with 26 bins (representing 2-week periods)\n",
    "# # # num_bins = int(num_days / 14)\n",
    "# # plt.hist(diff, bins=100)\n",
    "# # plt.scale('log')\n",
    "# transaction_df\n",
    "\n",
    "# # # Set the x-axis ticks to the start date of each bin\n",
    "# # bin_starts = pd.date_range(diff.min())\n",
    "# # plt.xticks(, rotation=45)\n",
    "\n",
    "# # # Set the x-axis label to the bin start dates and the y-axis label to the count of days in each bin\n",
    "# # plt.xlabel('Date (2-week bins)')\n",
    "# # plt.ylabel('Number of days')\n",
    "# # plt.title('Histogram of Days in 2-Week Bins')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time difference between each deposit\n",
    "\n",
    "# get the time difference between each deposit for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions[\"customer_id\"] == 92]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding 'Exited' Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create exited target variable\n",
    "end_date = pd.to_datetime('2020-5-31')\n",
    "exited = [(1 if row < end_date else 0) for row in df['final_transaction_date']]\n",
    "# (df['churn'] == 1) if (last_customer_date < end_date) else 0\n",
    "df['exited'] = exited\n",
    "df['exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Drop Na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Fix States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing states\n",
    "df['state'].replace(to_replace='TX', value='Texas', inplace=True)\n",
    "df['state'].replace(to_replace='CALIFORNIA', value='California', inplace=True)\n",
    "df['state'].replace(to_replace='MASS', value='Massachusetts', inplace=True)\n",
    "df['state'].replace(to_replace='NY', value='New York', inplace=True)\n",
    "# drop unidentifiable states\n",
    "df = df[(df.state != '-999') & (df.state != 'UNK') & (df.state != 'Australia')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Drop Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['dob','creation_date']\n",
    "df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_date'] = pd.to_datetime(\"31/05/2020\", dayfirst=True)\n",
    "\n",
    "# get the time difference between each deposit\n",
    "\n",
    "transaction_df=transactions\n",
    "transaction_df = transaction_df[transaction_df['deposit'] > 0]\n",
    "transaction_df['transaction_diff'] = (transaction_df.groupby('customer_id')['transaction_date'].diff().dt.days)\n",
    "transaction_df['transaction_diff'] = transaction_df['transaction_diff'].replace(np.nan, 0)\n",
    "\n",
    "# transaction_df[transaction_df[\"customer_id\"] == 92]\n",
    "\n",
    "# df_test = df.merge(transaction_df[['customer_id','avg_transaction_diff']], how='left', on='customer_id')\n",
    "# df_test.describe()\n",
    "# df_test\n",
    "\n",
    "# df\n",
    "# df['churned'] = (((df['final_date'] - df['final_deposit_date']).dt.days > df['avg_transaction_diff']))\n",
    "# print(df['churned'].head())\n",
    "\n",
    "# print(df['churned'].value_counts())\n",
    "df_test = df\n",
    "new_df3 = transaction_df[['customer_id', 'transaction_diff']]\n",
    "new_df3 = new_df3.groupby('customer_id')['transaction_diff'].agg('mean')\n",
    "df_test=df_test.merge(new_df3, how='left', on='customer_id', )\n",
    "df_test.rename(columns={'transaction_diff':'avg_dep_rate'}, inplace=True)\n",
    "df_test.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['final_date'] = pd.to_datetime(\"31/05/2020\")\n",
    "df_test['churned'] = (((df_test['final_date'] - df_test['final_deposit_date']).dt.days > df_test['avg_dep_rate']))\n",
    "\n",
    "print(df_test['churned'].value_counts())\n",
    "print(len(df_test))\n",
    "df_test['churned'].value_counts().to_list()\n",
    "\n",
    "print(df_test['churned'].value_counts().to_list()[1] / sum(df_test['churned'].value_counts().to_list()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The theory behind choosing this is as our churn definition stems from the fact that the bank is interested in savings account users that deposit regularly. \n",
    "# IF the average deposit rate for that customer is lower than the length of time elapsed since their last deposit to May 2020 plus some buffer to allow for the benefit of the doubt. \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((25531/(25531+88239)))\n",
    "print((96718/(96718+17052)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['time_since_last_deposit'] =df_test['final_date']-df_test['final_deposit_date']\n",
    "df_test['time_since_last_deposit']= (df_test['time_since_last_deposit'].dt.days)/365\n",
    "\n",
    "\n",
    "df_test.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANY OTHER CLEANING?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1941/365\n",
    "\n",
    "\n",
    "#frequency of people whos last transaction date was in that month \n",
    "\n",
    "\n",
    "# month "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle06_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9a958ae20cef41171190dad9680fd956436bd5c71ddb365bf564717bb4e8557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
